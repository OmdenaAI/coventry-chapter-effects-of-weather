{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69d25f1",
   "metadata": {},
   "source": [
    "<h1>Weather scraping, timeanddate.com</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f4d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class WeatherScrapper:\n",
    "    def __init__(self, year, month):\n",
    "        \"\"\"\n",
    "        timeanddate.com scrapper for temperature historic data in London.\n",
    "        :param year: Year\n",
    "        :param month: Month to collect temperature data\n",
    "        \"\"\"\n",
    "\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.days = calendar.monthrange(self.year, self.month)[1]\n",
    "        self.url = f'https://www.timeanddate.com/weather/uk/london/historic?month={month}&year={year}'\n",
    "        chromedriver = 'chromedriver'  # This needs to be set individually\n",
    "        os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "        self.driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "    def _load_html(self, day, latency):\n",
    "        \"\"\"\n",
    "        Loads web page for given year and month\n",
    "        :return: html object to be read with BeatifulSoup\n",
    "        \"\"\"\n",
    "\n",
    "        self.driver.get(self.url)\n",
    "        element = self.driver.find_element(by=By.CLASS_NAME, value='weatherLinks')\n",
    "        href = f'/weather/uk/london/historic?hd={self.year}{self.month:02d}{day:02d}'\n",
    "        link = self.driver.find_element(By.XPATH, value=f'//a[@href=\"{href}\"]')\n",
    "        self.driver.execute_script('arguments[0].click()', link)\n",
    "        time.sleep(latency)\n",
    "        html = self.driver.page_source\n",
    "        return html\n",
    "\n",
    "    def _load_weather_table(self, day, latency):\n",
    "        \"\"\"\n",
    "        Reads weather table with historic data\n",
    "        :param latency: wait time in seconds\n",
    "        :return: table rows with temperature\n",
    "        \"\"\"\n",
    "\n",
    "        html = self._load_html(day, latency)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        all_tables = soup.find_all('table')\n",
    "        weather_table = all_tables[1].children\n",
    "        table_content = []\n",
    "\n",
    "        for i in weather_table:\n",
    "            table_content.append(i)\n",
    "\n",
    "        body = table_content[1]\n",
    "        rows = body.find_all('tr')\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def get_weather(self, latency=0.5):\n",
    "        \"\"\"\n",
    "        Collects temperature data for all days in given month\n",
    "        :param latency: wait time in seconds\n",
    "        :return: DataFrame with temperature and timestamp\n",
    "        \"\"\"\n",
    "\n",
    "        data_df = pd.DataFrame()\n",
    "        for day in range(1, self.days+1):\n",
    "            while True:\n",
    "                rows = self._load_weather_table(day, latency)\n",
    "                data = []\n",
    "                day_from_html = int(rows[0].find_all('th')[0].text.split()[1])\n",
    "                date = f'{self.year}-{self.month:02d}-{day_from_html:02d}'\n",
    "                if day != day_from_html:\n",
    "                    print('---Missed day, trying again---')\n",
    "                    print(f'Looking for {day} day, instead got {day_from_html} from html')\n",
    "                    print('If this occurs often try to increase latency parameter')\n",
    "                    print('-'*10)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            for i in rows:\n",
    "                time_text = i.find_all('th')[0].text[0:5].split(':')\n",
    "                time = f'{time_text[0]}:{time_text[1]}'\n",
    "                timestamp_string = f'{date} {time}'\n",
    "                timestamp = datetime.strptime(timestamp_string, '%Y-%m-%d %H:%M')\n",
    "\n",
    "                temp_text = i.find_all('td')[1].text\n",
    "                temp_value = float(temp_text.split()[0])\n",
    "                description = i.find_all('td')[2].text[0:-1]\n",
    "                entry = {'timestamp': timestamp, 'temperature': temp_value, 'description': description}\n",
    "                data.append(entry)\n",
    "\n",
    "            data_df = data_df.append(pd.DataFrame(data))\n",
    "        data_df.reset_index(inplace=True)\n",
    "        data_df.drop('index', inplace=True, axis=1)\n",
    "\n",
    "        return data_df\n",
    "\n",
    "    def get_daylength(self):\n",
    "        \"\"\"\n",
    "        Collects length of day in hours for all days in given month\n",
    "        :return: list of dict\n",
    "        \"\"\"\n",
    "        url = f'https://www.timeanddate.com/sun/uk/london?month={self.month}&year={self.year}'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        month_daylength = []\n",
    "        for day in range(1, self.days + 1):\n",
    "            day_data = soup.find('tr', {'data-day': f'{day}'})\n",
    "            daylength = day_data.find('td', {'class': 'c tr sep-l'}).text\n",
    "            daylength = daylength.split(':')\n",
    "            hour, minutes, seconds = float(daylength[0]), float(daylength[1]), float(daylength[2])\n",
    "            daylength = hour + minutes/60 + seconds/60/60\n",
    "            day = {'timestamp': datetime.strptime(f'{self.year}-{self.month}-{day}', '%Y-%m-%d'),\n",
    "                   'daylength': daylength}\n",
    "            month_daylength.append(day)\n",
    "\n",
    "        return month_daylength\n",
    "\n",
    "\n",
    "class DataGather:\n",
    "    def __init__(self, start_year: int, start_month: int, end_year: int, end_month: int):\n",
    "        \"\"\"\n",
    "        :param start_year: Year of start of data collection period\n",
    "        :param start_month: Month of start of data collection period\n",
    "        :param end_year: Year of end of data collection period\n",
    "        :param end_month: Month of end of data collection period\n",
    "        \"\"\"\n",
    "        start_time_string = f'{start_year}-{start_month}-01'\n",
    "        end_time_string = f'{end_year}-{end_month}-01'\n",
    "        self.start_stamp = datetime.strptime(start_time_string, '%Y-%m-%d')\n",
    "        self.end_stamp = datetime.strptime(end_time_string, '%Y-%m-%d')\n",
    "        self.dates = pd.date_range(self.start_stamp, self.end_stamp, freq='MS').to_list()\n",
    "\n",
    "    def collect_weather(self, latency=0.5, save=True):\n",
    "        \"\"\"\n",
    "        Collects temperature data for given period\n",
    "        :param latency: wait time in seconds\n",
    "        :param save: if True saves data to a csv file in working directory\n",
    "        :return: DataFrame with temperature and timestamps\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame()\n",
    "        for i in self.dates:\n",
    "            year = i.year\n",
    "            month = i.month\n",
    "            print(f'Collecting for {year}-{month:02d}')\n",
    "            scrapper = WeatherScrapper(year, month)\n",
    "            month_data = scrapper.get_weather(latency)\n",
    "            data = data.append(month_data)\n",
    "        data.reset_index(inplace=True)\n",
    "        data.drop('index', inplace=True, axis=1)\n",
    "        if save:\n",
    "            data.to_csv('London_weather.txt')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def collect_daylight(self, save=True):\n",
    "        \"\"\"\n",
    "        Collects lenght of day for days in given period\n",
    "        :param save: if True saves data to a csv file in working directory\n",
    "        :return: DataFrame with length of day and timestamps\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame()\n",
    "        for i in self.dates:\n",
    "            year = i.year\n",
    "            month = i.month\n",
    "            print(f'Collecting day lenght for {year}-{month:02d}')\n",
    "            scrapper = WeatherScrapper(year, month)\n",
    "            month_data = scrapper.get_daylength()\n",
    "            data = data.append(month_data)\n",
    "        data.reset_index(inplace=True)\n",
    "        data.drop('index', inplace=True, axis=1)\n",
    "        if save:\n",
    "            data.to_csv('London_daylight.txt')\n",
    "        return data\n",
    "\n",
    "class WeatherProcessor:\n",
    "    def __init__(self, filename=None):\n",
    "        if filename is None:\n",
    "            self.data = pd.read_csv('London_weather.txt', parse_dates=['timestamp'], index_col=0)\n",
    "\n",
    "        else:\n",
    "            self.file = filename\n",
    "            self.data = pd.read_csv(self.file, parse_dates=['timestamp'], index_col=0)\n",
    "\n",
    "    def daily(self):\n",
    "        \"\"\"\n",
    "        Creates daily weather data from hourly\n",
    "        :return: DataFrame\n",
    "        \"\"\"\n",
    "        data = self.data.copy()\n",
    "        daily = pd.DataFrame()\n",
    "        for i in range(data.shape[0]):\n",
    "            data.loc[i, 'timestamp'] = data.loc[i, 'timestamp'].date()\n",
    "\n",
    "        grouped = data.groupby(by='timestamp')\n",
    "\n",
    "        for i in grouped:\n",
    "\n",
    "            index = i[1].index[0]\n",
    "            day = i[1].loc[index, 'timestamp']\n",
    "            temp = i[1]['temperature'].mean()\n",
    "            description = i[1]['description'].mode()\n",
    "\n",
    "            day_entry = [{'timestamp':day, 'temperature': temp, 'description': description[0]}]\n",
    "            day_data = pd.DataFrame(day_entry)\n",
    "            daily = daily.append(day_data)\n",
    "\n",
    "        daily.reset_index(inplace=True)\n",
    "        daily.drop('index', inplace=True, axis=1)\n",
    "        daily['temperature'] = daily['temperature'].round(decimals=1)\n",
    "\n",
    "        return daily\n",
    "\n",
    "    def add_daylight(self, daily_data, filename=None):\n",
    "        if filename is None:\n",
    "            daylight = pd.read_csv('London_daylight.txt', parse_dates=['timestamp'], index_col=0)\n",
    "        else:\n",
    "            daylight = pd.read_csv(filename, parse_dates=['timestamp'], index_col=0)\n",
    "\n",
    "        data = pd.concat([daily_data, daylight], axis=1)\n",
    "        data = data.iloc[:, [0, 1, 2, -1]]\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785d11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting for 2020-12\n",
      "Collecting for 2021-01\n",
      "Collecting for 2021-02\n",
      "Collecting for 2021-03\n",
      "Collecting for 2021-04\n",
      "Collecting for 2021-05\n",
      "Collecting for 2021-06\n",
      "---Missed day, trying again---\n",
      "Looking for 8 day, instead got 1 from html\n",
      "----------\n",
      "Collecting for 2021-07\n",
      "Collecting for 2021-08\n",
      "Collecting for 2021-09\n",
      "Collecting for 2021-10\n",
      "---Missed day, trying again---\n",
      "Looking for 10 day, instead got 1 from html\n",
      "----------\n",
      "Collecting for 2021-11\n",
      "Collecting for 2021-12\n",
      "---Missed day, trying again---\n",
      "Looking for 10 day, instead got 1 from html\n",
      "----------\n",
      "---Missed day, trying again---\n",
      "Looking for 21 day, instead got 1 from html\n",
      "----------\n",
      "Collecting for 2022-01\n",
      "Collecting for 2022-02\n",
      "Collecting for 2022-03\n",
      "Collecting for 2020-12\n",
      "Collecting for 2021-01\n",
      "Collecting for 2021-02\n",
      "Collecting for 2021-03\n",
      "Collecting for 2021-04\n",
      "Collecting for 2021-05\n",
      "Collecting for 2021-06\n",
      "Collecting for 2021-07\n",
      "Collecting for 2021-08\n",
      "Collecting for 2021-09\n",
      "Collecting for 2021-10\n",
      "Collecting for 2021-11\n",
      "Collecting for 2021-12\n",
      "Collecting for 2022-01\n",
      "Collecting for 2022-02\n",
      "Collecting for 2022-03\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "start_year = 2020\n",
    "start_month = 12\n",
    "end_year = 2022\n",
    "end_month = 3\n",
    "\n",
    "data = DataGather(start_year, start_month, end_year, end_month)\n",
    "data.collect_weather(latency=0.5)\n",
    "data.collect_daylight()\n",
    "wpr = WeatherProcessor()\n",
    "daily = wpr.daily()\n",
    "daily = wpr.add_daylight(daily)\n",
    "daily.to_csv('Daily_weather.txt')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
